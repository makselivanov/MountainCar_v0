{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(p):\n",
    "    return int(round((p + 1.2) * 100)) #[0, 180]\n",
    "def get_velocity(v):\n",
    "    return int(round((v + 0.07) * 1000)) #[0, 140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(533239)\n",
    "max_score = 200\n",
    "max_episodes = 200\n",
    "lf, df = 0.6, 0.9\n",
    "h, w = 181, 141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, episodes, lf, df, max_score, h, w):\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.qarr = np.random.randint(max_score, size=(h, w, 3))\n",
    "        self.lf, self.df = lf, df\n",
    "    \n",
    "    def choice(self, p, v):\n",
    "        index = 0\n",
    "        for i in range(1, 3):\n",
    "            if self.qarr[p, v, i] > self.qarr[p, v, index]:\n",
    "                index = i\n",
    "        return index\n",
    "    \n",
    "    def start_game(self):\n",
    "        try:\n",
    "            observation = self.env.reset()\n",
    "            done = False\n",
    "            prev_p = get_position(observation[0])\n",
    "            prev_v = get_velocity(observation[1])\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = self.choice(prev_p, prev_v)\n",
    "                observation, reward, done, _ = self.env.step(action)\n",
    "                p = get_position(observation[0])\n",
    "                v = get_velocity(observation[1])\n",
    "                self.qarr[prev_p, prev_v, action] += self.lf * (reward + self.df * self.qarr[p, v, self.choice(p, v)] - self.qarr[prev_p, prev_v, action])\n",
    "                if done:\n",
    "                    break\n",
    "        finally:\n",
    "            self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "agent = Agent(env, max_episodes, lf, df, max_score, h, w)\n",
    "agent.start_game()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
